{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7e84cd0e-0680-44b6-b541-643e189c72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are building a character level decoder-only language model \n",
    "# original paper Transformer is a encoder-decoder language model for machine translation. \n",
    "# best explanation of attention in tranformer: https://jalammar.github.io/illustrated-transformer/\n",
    "# encoder-decoder: unmasked attention to both past and future inside encoder; decoder takes K, V from the final output of encoder\n",
    "# v.\n",
    "# decoder-only: attention only to the past "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "024ecddd-3a53-437b-a64a-4d71b22b7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "540e6417-44ff-46db-9311-efec7ea7a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f19be0e3-12a0-4270-90c0-a629e82d19e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# vocab = set(list(text))\n",
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a751753d-4942-4348-9c05-ba31786945f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# create mapping from char to integers\n",
    "stoi = {s:i for i, s in enumerate(vocab)}\n",
    "itos = {i:s for s, i, in stoi.items()}\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7ee40b63-8324-46e6-948d-5e9b2aefcc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 59, 62, 47, 39, 53]\n",
      "yuxiao\n"
     ]
    }
   ],
   "source": [
    "# define 2 lambda functions\n",
    "# encode: turn a string to a list of integers\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "# decode: turn a list of integer to string\n",
    "decode = lambda ixs: \"\".join([itos[ix] for ix in ixs])\n",
    "print(encode(\"yuxiao\"))\n",
    "print(decode(encode(\"yuxiao\")))\n",
    "\n",
    "# commonly used word level tokenizer that break word into sub-words are SentencePiece, tiktoken, both used BPE (\"byte-pair-encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a0a13c3-e36d-4165-b3b3-4c9bdad3d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "[88, 2821, 13481]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "gpt2_encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "print(gpt2_encoder.n_vocab)\n",
    "print(gpt2_encoder.encode(\"yuxiao\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1fb9fda4-5b2f-4f48-affa-e7af95f9706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59]\n",
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# let's encode the whole document into list, then to torch tensors\n",
    "print(encode(text)[:100])\n",
    "# data = torch.tensor(encode(text))  #torch.int64\n",
    "data = torch.tensor(encode(text), dtype=torch.long)  \n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "578c2b93-1311-4855-ab5c-c53d7fda59a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854\n",
      "train data:  1003854\n",
      "val data:v  111540\n"
     ]
    }
   ],
   "source": [
    "# split data into train and validation\n",
    "n = int(len(data) * 0.9)\n",
    "print(n)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(\"train data: \", len(train_data))\n",
    "print(\"val data:v \", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5c761822-de2e-493f-b294-0f70d02886ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_x:  tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "block_y:  tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "input: tensor([18]), target = 47\n",
      "input: tensor([18, 47]), target = 56\n",
      "input: tensor([18, 47, 56]), target = 57\n",
      "input: tensor([18, 47, 56, 57]), target = 58\n",
      "input: tensor([18, 47, 56, 57, 58]), target = 1\n",
      "input: tensor([18, 47, 56, 57, 58,  1]), target = 15\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15]), target = 47\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15, 47]), target = 58\n"
     ]
    }
   ],
   "source": [
    "# let's consider the time dimension to build x and y\n",
    "\n",
    "# we will build x from len of 1 all the way to len of 7, various length help us do better ar reference, when given input as short as 1 char, \n",
    "# model knows how to predict next because it's seen it in the training data\n",
    "\n",
    "block_size = 8   # the longest context window  # for every block_size in the data, we'll build 7 examples\n",
    "\n",
    "block_x = data[:block_size]  # the first 7 chars\n",
    "block_y = data[1:block_size+1]  # shifted back by 1\n",
    "print(\"block_x: \", block_x)\n",
    "print(\"block_y: \", block_y)\n",
    "for i in range(len(block_x)):\n",
    "    input = block_x[:i+1]\n",
    "    target = block_y[i]\n",
    "    print(f\"input: {input}, target = {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f102b26c-3920-4326-b09f-ba6661d7658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 1])\n",
      "tensor([2, 1, 1, 1])\n",
      "tensor([2, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "# randomly select 4 independent data examples of sequence of 8, may start from anywhere\n",
    "# if data len of 10,  block_size = 8, sampel from position [0,1,2]\n",
    "data = torch.tensor([9,8,7,1,2,3,4,5,6,0])\n",
    "for _ in range(3):  # it takes 2.5 iterations of getting batch to cover the whole data\n",
    "    ix = torch.randint(low=0, high = len(data) - block_size + 1, size=(batch_size,))  # high is exclusive, size=tuple define output shape\n",
    "    print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8d91e0bc-a991-448f-945c-fc9a213e10ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[47, 64, 43, 52, 10,  0, 14, 43],\n",
      "        [47, 64, 43, 52, 10,  0, 14, 43],\n",
      "        [47, 58, 47, 64, 43, 52, 10,  0],\n",
      "        [43, 52, 10,  0, 14, 43, 44, 53]])\n",
      "tensor([[64, 43, 52, 10,  0, 14, 43, 44],\n",
      "        [64, 43, 52, 10,  0, 14, 43, 44],\n",
      "        [58, 47, 64, 43, 52, 10,  0, 14],\n",
      "        [52, 10,  0, 14, 43, 44, 53, 56]])\n",
      "input = tensor([47]), target = 64\n",
      "input = tensor([47, 64]), target = 43\n",
      "input = tensor([47, 64, 43]), target = 52\n",
      "input = tensor([47, 64, 43, 52]), target = 10\n",
      "input = tensor([47, 64, 43, 52, 10]), target = 0\n",
      "input = tensor([47, 64, 43, 52, 10,  0]), target = 14\n",
      "input = tensor([47, 64, 43, 52, 10,  0, 14]), target = 43\n",
      "input = tensor([47, 64, 43, 52, 10,  0, 14, 43]), target = 44\n",
      "input = tensor([47]), target = 64\n",
      "input = tensor([47, 64]), target = 43\n",
      "input = tensor([47, 64, 43]), target = 52\n",
      "input = tensor([47, 64, 43, 52]), target = 10\n",
      "input = tensor([47, 64, 43, 52, 10]), target = 0\n",
      "input = tensor([47, 64, 43, 52, 10,  0]), target = 14\n",
      "input = tensor([47, 64, 43, 52, 10,  0, 14]), target = 43\n",
      "input = tensor([47, 64, 43, 52, 10,  0, 14, 43]), target = 44\n",
      "input = tensor([47]), target = 58\n",
      "input = tensor([47, 58]), target = 47\n",
      "input = tensor([47, 58, 47]), target = 64\n",
      "input = tensor([47, 58, 47, 64]), target = 43\n",
      "input = tensor([47, 58, 47, 64, 43]), target = 52\n",
      "input = tensor([47, 58, 47, 64, 43, 52]), target = 10\n",
      "input = tensor([47, 58, 47, 64, 43, 52, 10]), target = 0\n",
      "input = tensor([47, 58, 47, 64, 43, 52, 10,  0]), target = 14\n",
      "input = tensor([43]), target = 52\n",
      "input = tensor([43, 52]), target = 10\n",
      "input = tensor([43, 52, 10]), target = 0\n",
      "input = tensor([43, 52, 10,  0]), target = 14\n",
      "input = tensor([43, 52, 10,  0, 14]), target = 43\n",
      "input = tensor([43, 52, 10,  0, 14, 43]), target = 44\n",
      "input = tensor([43, 52, 10,  0, 14, 43, 44]), target = 53\n",
      "input = tensor([43, 52, 10,  0, 14, 43, 44, 53]), target = 56\n"
     ]
    }
   ],
   "source": [
    "# data loader: get batch of chunks ofdata \n",
    "\n",
    "torch.manual_seed(1337)\n",
    "# same get batch for both train data and val data, return one batch of x and y\n",
    "def get_batch(split):\n",
    "    data = train_data[:20] if split == \"train\" else val_data\n",
    "    ix = torch.randint(low=0, high = len(data) - block_size + 1, size=(batch_size,))\n",
    "    xb = torch.stack([data[startpos: startpos + block_size] for startpos in ix]) \n",
    "    # stack takes list of tensors and stack them veritically, along dim=0\n",
    "    yb = torch.stack([data[startpos+1: startpos + block_size+1] for startpos in ix])\n",
    "\n",
    "    return xb, yb\n",
    "    \n",
    "xb, yb = get_batch(\"train\")\n",
    "print(xb)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        input = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"input = {input}, target = {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b2a9c18c-6a46-4003-bdfe-1c6282682488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first build the simplest NN language model\n",
    "# input will be just one char\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # self.embeddings = torch.randn(vocab_size, vocab_size) # serve as the lookup table, turn a char into vector of embeds\n",
    "        self.embedding_table = nn.Embedding(vocab_size, vocab_size)  # Embedding: variables from ~N(0,1)\n",
    "                                      \n",
    "    def forward(self, input, target):   # idx: this is a bigram setting, so input will be only one char, here pass its integer\n",
    "        # input and target are shape of (B (batch_size) , T (block_size) )\n",
    "        \n",
    "        logits = self.embedding_table(input)\n",
    "        print(\"logits shape: \", logits.shape)\n",
    "        \n",
    "        # wrong: loss = F.cross_entropy(logits, target)  \n",
    "        # cross_entropy expect input has to be a Tensor of size (C) for unbatched input, (minibatch,C) or (minibatch, C, d1, ..dk) with K>=1\n",
    "        # for the K-dimensional case. The last being useful for higher dimension inputs, such as computing cross entropy loss per-pixel for 2D images \n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        target = target.view(B*T)\n",
    "\n",
    "        loss = F.cross_entropy(logits, target)  # comply with (minibatch,C)\n",
    "        return logits, loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a13ef3e-5e86-4ea7-9052-8a2a3011f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape:  torch.Size([4, 8, 65])\n",
      "torch.Size([32, 65])\n",
      "tensor(4.3751, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bigram_model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = bigram_model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "# expected loss\n",
    "# prob = 1/65\n",
    "# - ln(1/65) = 4.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0a1732cd-355e-47c3-a59e-4a670e744d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # self.embeddings = torch.randn(vocab_size, vocab_size) # serve as the lookup table, turn a char into vector of embeds\n",
    "        self.embedding_table = nn.Embedding(vocab_size, vocab_size)  # Embedding: variables from ~N(0,1)\n",
    "                                      \n",
    "    def forward(self, input, target=None):  # make target optional\n",
    "        \n",
    "        logits = self.embedding_table(input) \n",
    "        B, T, C = logits.shape\n",
    "        \n",
    "        if target is None:  \n",
    "            loss = None    # logits returned will be shape (B, T, C)\n",
    "        else:\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)  # comply with (minibatch,C)\n",
    "        return logits, loss\n",
    "\n",
    "    # def generate(self, input, max_new_tokens):  # work for bigram\n",
    "    #     out = []\n",
    "    #     for i in range(max_new_tokens):\n",
    "    #         # nn.Module  When you create an instance of this module and call it with input data, \n",
    "    #         # PyTorch internally calls the forward method, passing the input data to it.\n",
    "    #         logits, _ = self(input)\n",
    "    #         # print(\"logits shape: \", logits.shape)\n",
    "    #         probs = F.softmax(logits, dim=-1)\n",
    "    #         idx_next = torch.multinomial(probs, num_samples=1)\n",
    "    #         # print(\"idx_next shape: \", idx_next.shape)\n",
    "    #         out.append(idx_next.item())\n",
    "    #         input = idx_next\n",
    "    #     return out\n",
    "    \n",
    "    def generate(self, input, max_new_tokens):  # more general, allow to condition on more previous chars\n",
    "    \n",
    "        for i in range(max_new_tokens):\n",
    "            # nn.Module  When you create an instance of this module and call it with input data, \n",
    "            # PyTorch internally calls the forward method, passing the input data to it.\n",
    "            logits, _ = self(input)\n",
    "            # print(\"logits shape: \", logits.shape)  # (B,T,C)\n",
    "            logits = logits[:, -1, :]   # becomes (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)    # (B, C)\n",
    "            # print(\"probs shape: \", probs.shape)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # print(\"idx_next shape: \", idx_next.shape)\n",
    "            input = torch.cat((input, idx_next), dim=1)\n",
    "\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6ab7002c-fa9e-4702-86c8-48e6a93c636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.3875, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bigram_model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = bigram_model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "774652ed-8763-4bb9-bcbf-fd53d1ae6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n",
      "torch.Size([1, 1])\n",
      "out shape:  torch.Size([1, 101])\n",
      "\n",
      "lfJeukRuaRJKXAYtXzfJ:HEPiu--sDioi;ILCo3pHNTmDwJsfheKRxZCFs\n",
      "lZJ XQc?:s:HEzEnXalEPklcPU cL'DpdLCafBheH\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([0]).view(1, 1)  # (B, T)\n",
    "print(input)\n",
    "print(input.shape)\n",
    "out = bigram_model.generate(input, 100)\n",
    "print(\"out shape: \", out.shape)  # [1, 101])\n",
    "print(decode(out[0].tolist()))   # this is random model (not trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7eca523a-06c8-4e16-895f-23db7b09cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# now let's train the model\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'  # mac uses AMD gpu not cuda, \n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "# Starting with PyTorch 1.12, support for Apple's Metal Performance Shaders (MPS) backend has been introduced, which allows you to utilize the GPU on newer Macs with Apple Silicon (M1, M2, etc.)\n",
    "print(device)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 32\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(low=0, high = len(data) - block_size + 1, size=(batch_size,))\n",
    "    xb = torch.stack([data[startpos: startpos + block_size] for startpos in ix]) \n",
    "    # stack takes list of tensors and stack them veritically, along dim=0\n",
    "    yb = torch.stack([data[startpos+1: startpos + block_size+1] for startpos in ix])\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    return xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8463c95e-f9e1-4aa2-a35b-e445a097d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5216684341430664\n"
     ]
    }
   ],
   "source": [
    "bigram_model = BigramLanguageModel(vocab_size)\n",
    "model = bigram_model.to(device)\n",
    "\n",
    "learning_rate = 1e-2   # default 0.001, for our simple model, can be bigger\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for step in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    # print(xb.shape)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())   # start from 4.+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e83887de-d4ae-4c62-9d7c-caae12f1546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BE:\n",
      "\n",
      "Hortrny antres r t'diardesit t cr acheed ingeakint shemandain, y,\n",
      "SALAd tit ps y, ld ost, s, INGRY achit d n so's.\n",
      "HABELO, hin twincklobeanst.\n",
      "Graghintharofourthisckererorren'hethowimeve d\n",
      "\n",
      "\n",
      "Pr aven thenin,\n",
      "HEORord f ucu ord?\n",
      "Ge t, cce's thik sthimig ht pout thund anoforkse s\n",
      "Thit tsine\n",
      "Houthea\n"
     ]
    }
   ],
   "source": [
    "# try generate again\n",
    "out = model.generate(input=torch.tensor([0]).view(1,1), max_new_tokens=300)\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cf39f08e-533e-48e4-a29a-d8341d359cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add evaluation part\n",
    "eval_interval = 300\n",
    "eval_iters = 200\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()   # switch model mode\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):  # pick 200 batches inside train, pick 200 batches inside val\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()  # store 200 losses\n",
    "        out[split] = losses.mean()\n",
    "    model.train()   # switch model mode\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "13a2ef0c-5f45-47eb-998a-092c842ccc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.6412, val loss 4.6621\n",
      "step 300: train loss 2.7940, val loss 2.8243\n",
      "step 600: train loss 2.5473, val loss 2.5809\n",
      "step 900: train loss 2.4977, val loss 2.5270\n",
      "step 1200: train loss 2.4846, val loss 2.5036\n",
      "step 1500: train loss 2.4711, val loss 2.5004\n",
      "step 1800: train loss 2.4677, val loss 2.4851\n",
      "step 2100: train loss 2.4641, val loss 2.4986\n",
      "step 2400: train loss 2.4645, val loss 2.4877\n",
      "step 2700: train loss 2.4629, val loss 2.4895\n"
     ]
    }
   ],
   "source": [
    "bigram_model = BigramLanguageModel(vocab_size)\n",
    "model = bigram_model.to(device)\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "learning_rate = 1e-2 \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "max_iters = 3000\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "81aa0c5a-caee-4e52-bf9c-de78d9d1f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I nt rray ngestyockind m murs, in mamybalorenyongmyooe, d Vofetthindy st\n",
      "Hefil brveseay alsteanerm to, oupomp rede d pre h, gavitfithrer'GENUpsts lathindKIO:\n",
      "Berouerse IOLUED d nghathicerire.\n",
      "II IS:\n",
      "Yok, pequt f keithunghaned t\n",
      "The orerrofe fisck.\n",
      "MUCI t wovyonon-hu he nd yot wilercet icis ig y onee\n"
     ]
    }
   ],
   "source": [
    "# try generate again\n",
    "out = model.generate(input=torch.tensor([0]).view(1,1).to(device), max_new_tokens=300)  # torch.tensor is built-in, not a Tensor\n",
    "# out = model.generate(input=torch.LongTensor([0]).view(1,1).to(device), max_new_tokens=300)\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da20f3d-d398-400e-943f-85e2b3140bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f7c5a-5d66-47a9-875c-a727c1ad097c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
